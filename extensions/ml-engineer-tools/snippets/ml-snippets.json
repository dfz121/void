{
    "PyTorch Model Template": {
        "prefix": "torch-model",
        "body": [
            "import torch",
            "import torch.nn as nn",
            "import torch.optim as optim",
            "",
            "class ${1:ModelName}(nn.Module):",
            "    def __init__(self, ${2:input_size}, ${3:hidden_size}, ${4:output_size}):",
            "        super(${1:ModelName}, self).__init__()",
            "        self.fc1 = nn.Linear(${2:input_size}, ${3:hidden_size})",
            "        self.relu = nn.ReLU()",
            "        self.fc2 = nn.Linear(${3:hidden_size}, ${4:output_size})",
            "        ",
            "    def forward(self, x):",
            "        out = self.fc1(x)",
            "        out = self.relu(out)",
            "        out = self.fc2(out)",
            "        return out",
            "",
            "# Initialize model",
            "model = ${1:ModelName}(${2:input_size}, ${3:hidden_size}, ${4:output_size})",
            "criterion = nn.CrossEntropyLoss()",
            "optimizer = optim.Adam(model.parameters(), lr=${5:0.001})"
        ],
        "description": "PyTorch model template with forward pass"
    },
    
    "TensorFlow Model Template": {
        "prefix": "tf-model",
        "body": [
            "import tensorflow as tf",
            "from tensorflow.keras import layers, Model",
            "",
            "class ${1:ModelName}(Model):",
            "    def __init__(self, ${2:num_classes}):",
            "        super(${1:ModelName}, self).__init__()",
            "        self.dense1 = layers.Dense(${3:128}, activation='relu')",
            "        self.dropout = layers.Dropout(${4:0.2})",
            "        self.dense2 = layers.Dense(${2:num_classes}, activation='softmax')",
            "        ",
            "    def call(self, inputs, training=False):",
            "        x = self.dense1(inputs)",
            "        x = self.dropout(x, training=training)",
            "        return self.dense2(x)",
            "",
            "# Initialize model",
            "model = ${1:ModelName}(${2:num_classes})",
            "model.compile(optimizer='adam',",
            "              loss='sparse_categorical_crossentropy',",
            "              metrics=['accuracy'])"
        ],
        "description": "TensorFlow/Keras model template"
    },
    
    "Training Loop PyTorch": {
        "prefix": "torch-train",
        "body": [
            "# Training loop",
            "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
            "model.to(device)",
            "",
            "for epoch in range(${1:num_epochs}):",
            "    model.train()",
            "    running_loss = 0.0",
            "    ",
            "    for batch_idx, (data, target) in enumerate(train_loader):",
            "        data, target = data.to(device), target.to(device)",
            "        ",
            "        optimizer.zero_grad()",
            "        output = model(data)",
            "        loss = criterion(output, target)",
            "        loss.backward()",
            "        optimizer.step()",
            "        ",
            "        running_loss += loss.item()",
            "        ",
            "        if batch_idx % ${2:100} == 0:",
            "            print(f'Epoch [{epoch+1}/${1:num_epochs}], Step [{batch_idx}], Loss: {loss.item():.4f}')",
            "    ",
            "    print(f'Epoch [{epoch+1}/${1:num_epochs}] Average Loss: {running_loss/len(train_loader):.4f}')"
        ],
        "description": "PyTorch training loop with GPU support"
    },
    
    "Data Preprocessing": {
        "prefix": "ml-preprocess",
        "body": [
            "import pandas as pd",
            "import numpy as np",
            "from sklearn.model_selection import train_test_split",
            "from sklearn.preprocessing import StandardScaler",
            "",
            "# Load data",
            "df = pd.read_csv('${1:data.csv}')",
            "",
            "# Prepare features and target",
            "X = df.drop('${2:target_column}', axis=1)",
            "y = df['${2:target_column}']",
            "",
            "# Split data",
            "X_train, X_test, y_train, y_test = train_test_split(",
            "    X, y, test_size=${3:0.2}, random_state=${4:42})",
            "",
            "# Scale features",
            "scaler = StandardScaler()",
            "X_train_scaled = scaler.fit_transform(X_train)",
            "X_test_scaled = scaler.transform(X_test)"
        ],
        "description": "Data preprocessing pipeline"
    },
    
    "CNN Architecture": {
        "prefix": "cnn-model",
        "body": [
            "import torch.nn as nn",
            "",
            "class ${1:CNNModel}(nn.Module):",
            "    def __init__(self, ${2:num_classes}):",
            "        super(${1:CNNModel}, self).__init__()",
            "        ",
            "        self.conv_layers = nn.Sequential(",
            "            nn.Conv2d(${3:3}, ${4:32}, kernel_size=3, stride=1, padding=1),",
            "            nn.ReLU(),",
            "            nn.MaxPool2d(kernel_size=2, stride=2),",
            "            ",
            "            nn.Conv2d(${4:32}, ${5:64}, kernel_size=3, stride=1, padding=1),",
            "            nn.ReLU(),",
            "            nn.MaxPool2d(kernel_size=2, stride=2),",
            "            ",
            "            nn.Conv2d(${5:64}, ${6:128}, kernel_size=3, stride=1, padding=1),",
            "            nn.ReLU(),",
            "            nn.AdaptiveAvgPool2d((1, 1))",
            "        )",
            "        ",
            "        self.classifier = nn.Sequential(",
            "            nn.Flatten(),",
            "            nn.Dropout(${7:0.5}),",
            "            nn.Linear(${6:128}, ${2:num_classes})",
            "        )",
            "    ",
            "    def forward(self, x):",
            "        x = self.conv_layers(x)",
            "        x = self.classifier(x)",
            "        return x"
        ],
        "description": "CNN architecture template"
    },
    
    "LSTM Model": {
        "prefix": "lstm-model",
        "body": [
            "import torch.nn as nn",
            "",
            "class ${1:LSTMModel}(nn.Module):",
            "    def __init__(self, ${2:input_size}, ${3:hidden_size}, ${4:num_layers}, ${5:output_size}):",
            "        super(${1:LSTMModel}, self).__init__()",
            "        self.hidden_size = ${3:hidden_size}",
            "        self.num_layers = ${4:num_layers}",
            "        ",
            "        self.lstm = nn.LSTM(${2:input_size}, ${3:hidden_size}, ${4:num_layers}, batch_first=True)",
            "        self.fc = nn.Linear(${3:hidden_size}, ${5:output_size})",
            "    ",
            "    def forward(self, x):",
            "        # Initialize hidden state",
            "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)",
            "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)",
            "        ",
            "        # Forward propagate LSTM",
            "        out, _ = self.lstm(x, (h0, c0))",
            "        ",
            "        # Decode the hidden state of the last time step",
            "        out = self.fc(out[:, -1, :])",
            "        return out"
        ],
        "description": "LSTM model template for sequence processing"
    },
    
    "ML Evaluation": {
        "prefix": "ml-eval",
        "body": [
            "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix",
            "import matplotlib.pyplot as plt",
            "import seaborn as sns",
            "",
            "# Make predictions",
            "y_pred = model.predict(X_test)",
            "",
            "# Calculate metrics",
            "accuracy = accuracy_score(y_test, y_pred)",
            "print(f'Accuracy: {accuracy:.4f}')",
            "",
            "# Classification report",
            "print('\\nClassification Report:')",
            "print(classification_report(y_test, y_pred))",
            "",
            "# Confusion matrix",
            "cm = confusion_matrix(y_test, y_pred)",
            "plt.figure(figsize=(8, 6))",
            "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')",
            "plt.title('Confusion Matrix')",
            "plt.ylabel('True Label')",
            "plt.xlabel('Predicted Label')",
            "plt.show()"
        ],
        "description": "Model evaluation with metrics and visualization"
    },
    
    "Hyperparameter Tuning": {
        "prefix": "hyperparam-tune",
        "body": [
            "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV",
            "",
            "# Define parameter grid",
            "param_grid = {",
            "    '${1:parameter1}': [${2:value1}, ${3:value2}, ${4:value3}],",
            "    '${5:parameter2}': [${6:value1}, ${7:value2}],",
            "    '${8:parameter3}': [${9:value1}, ${10:value2}]",
            "}",
            "",
            "# Grid search",
            "grid_search = GridSearchCV(",
            "    estimator=${11:model},",
            "    param_grid=param_grid,",
            "    cv=${12:5},",
            "    scoring='${13:accuracy}',",
            "    n_jobs=-1,",
            "    verbose=1",
            ")",
            "",
            "# Fit and find best parameters",
            "grid_search.fit(X_train, y_train)",
            "print(f'Best parameters: {grid_search.best_params_}')",
            "print(f'Best score: {grid_search.best_score_:.4f}')",
            "",
            "# Use best model",
            "best_model = grid_search.best_estimator_"
        ],
        "description": "Hyperparameter tuning with GridSearchCV"
    }
}